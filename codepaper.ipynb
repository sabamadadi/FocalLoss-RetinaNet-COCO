{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T15:05:24.354510Z","iopub.execute_input":"2024-05-17T15:05:24.355269Z","iopub.status.idle":"2024-05-17T15:05:25.333716Z","shell.execute_reply.started":"2024-05-17T15:05:24.355234Z","shell.execute_reply":"2024-05-17T15:05:25.332803Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:05:25.335576Z","iopub.execute_input":"2024-05-17T15:05:25.336045Z","iopub.status.idle":"2024-05-17T15:05:38.901763Z","shell.execute_reply.started":"2024-05-17T15:05:25.336011Z","shell.execute_reply":"2024-05-17T15:05:38.900805Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.models.detection import RetinaNet\nfrom torchvision.datasets import CocoDetection\nfrom pycocotools.coco import COCO\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:05:38.903188Z","iopub.execute_input":"2024-05-17T15:05:38.903493Z","iopub.status.idle":"2024-05-17T15:05:44.997980Z","shell.execute_reply.started":"2024-05-17T15:05:38.903463Z","shell.execute_reply":"2024-05-17T15:05:44.997020Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntrain_dataset = CocoDetection(root='/kaggle/input/coco-2017-dataset/coco2017/train2017', annFile='/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_train2017.json', transform=transform)\nval_dataset = CocoDetection(root='/kaggle/input/coco-2017-dataset/coco2017/val2017', annFile='/kaggle/input/coco-2017-dataset/coco2017/annotations/instances_val2017.json', transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)), drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)), drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:05:45.000157Z","iopub.execute_input":"2024-05-17T15:05:45.000605Z","iopub.status.idle":"2024-05-17T15:06:13.172363Z","shell.execute_reply.started":"2024-05-17T15:05:45.000578Z","shell.execute_reply":"2024-05-17T15:06:13.171338Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=24.65s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.98s)\ncreating index...\nindex created!\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        targets = torch.tensor(targets)\n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n        \n        if self.reduction == 'mean':\n            return F_loss.mean()\n        elif self.reduction == 'sum':\n            return F_loss.sum()\n        else:\n            return F_loss\n\nfocal_loss = FocalLoss()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:13.173374Z","iopub.execute_input":"2024-05-17T15:06:13.173634Z","iopub.status.idle":"2024-05-17T15:06:13.183222Z","shell.execute_reply.started":"2024-05-17T15:06:13.173611Z","shell.execute_reply":"2024-05-17T15:06:13.182236Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Backbone(nn.Module):\n    def __init__(self, model_name='resnet50'):\n        super(Backbone, self).__init__()\n        if model_name == 'resnet50':\n            resnet = models.resnet50(pretrained=True)\n        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n\n    def forward(self, x):\n        return self.backbone(x)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:13.184330Z","iopub.execute_input":"2024-05-17T15:06:13.184632Z","iopub.status.idle":"2024-05-17T15:06:13.196868Z","shell.execute_reply.started":"2024-05-17T15:06:13.184608Z","shell.execute_reply":"2024-05-17T15:06:13.196102Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class FeaturePyramidNetwork(nn.Module):\n    def __init__(self, C3_size, C4_size, C5_size, feature_size=256):\n        super(FeaturePyramidNetwork, self).__init__()\n\n        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=1, stride=1, padding=0)\n        self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n\n        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=1, stride=1, padding=0)\n        self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n\n        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=1, stride=1, padding=0)\n        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=1, padding=1)\n\n        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=3, stride=2, padding=1)\n        self.P7 = nn.Conv2d(feature_size, feature_size, kernel_size=3, stride=2, padding=1)\n\n    def forward(self, C3, C4, C5):\n        P5_x = self.P5_1(C5)\n        P5_upsampled = F.interpolate(P5_x, scale_factor=2, mode=\"nearest\")\n        P5 = self.P5_2(P5_x)\n\n        P4_x = self.P4_1(C4)\n        P4_x = P4_x + P5_upsampled\n        P4_upsampled = F.interpolate(P4_x, scale_factor=2, mode=\"nearest\")\n        P4 = self.P4_2(P4_x)\n\n        P3_x = self.P3_1(C3)\n        P3_x = P3_x + P4_upsampled\n        P3 = self.P3_2(P3_x)\n\n        P6 = self.P6(C5)\n        P7 = self.P7(F.relu(P6))\n\n        return [P3, P4, P5, P6, P7]\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:13.197928Z","iopub.execute_input":"2024-05-17T15:06:13.198276Z","iopub.status.idle":"2024-05-17T15:06:13.210131Z","shell.execute_reply.started":"2024-05-17T15:06:13.198251Z","shell.execute_reply":"2024-05-17T15:06:13.209244Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class SubNet(nn.Module):\n    def __init__(self, num_classes, num_anchors):\n        super(SubNet, self).__init__()\n        self.conv1 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(256, num_anchors * num_classes, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.relu(self.conv3(x))\n        x = self.relu(self.conv4(x))\n        return self.conv5(x)\n\nclass RetinaNet(nn.Module):\n    def __init__(self, num_classes, backbone):\n        super(RetinaNet, self).__init__()\n        self.backbone = backbone\n        fpn_sizes = [256, 512, 1024, 2048]  # Sizes of C3, C4, C5\n        self.fpn = FeaturePyramidNetwork(fpn_sizes[0], fpn_sizes[1], fpn_sizes[2])\n        self.num_anchors = 9\n        self.num_classes = num_classes\n        self.classification_head = SubNet(num_classes, self.num_anchors)\n        self.regression_head = SubNet(4, self.num_anchors)\n\n    def forward(self, x):\n        C3, C4, C5 = self.backbone(x)\n        features = self.fpn(C3, C4, C5)\n        classifications = [self.classification_head(f) for f in features]\n        regressions = [self.regression_head(f) for f in features]\n        return classifications, regressions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:13.211258Z","iopub.execute_input":"2024-05-17T15:06:13.211507Z","iopub.status.idle":"2024-05-17T15:06:13.225879Z","shell.execute_reply.started":"2024-05-17T15:06:13.211485Z","shell.execute_reply":"2024-05-17T15:06:13.225150Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\nnum_classes = 91  # COCO has 80 classes + background\n\nmodel.head.classification_head.num_classes = num_classes\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:13.226996Z","iopub.execute_input":"2024-05-17T15:06:13.227289Z","iopub.status.idle":"2024-05-17T15:06:15.343622Z","shell.execute_reply.started":"2024-05-17T15:06:13.227262Z","shell.execute_reply":"2024-05-17T15:06:15.342638Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_coco-eeacb38b.pth\n100%|██████████| 130M/130M [00:00<00:00, 147MB/s]  \n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"RetinaNet(\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=0.0)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-2): 3 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelP6P7(\n        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n    )\n  )\n  (anchor_generator): AnchorGenerator()\n  (head): RetinaNetHead(\n    (classification_head): RetinaNetClassificationHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 819, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (regression_head): RetinaNetRegressionHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (bbox_reg): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10):\n    model.train()\n    running_loss = 0.0\n    data_loader = tqdm(data_loader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n    \n    for i, (images, targets) in enumerate(data_loader):\n        images = list(image.to(device) for image in images)\n        \n        valid_targets = []\n        for t in targets:\n            if len(t) == 0:\n                valid_targets.append({'boxes': torch.zeros((0, 4), dtype=torch.float32).to(device),\n                                      'labels': torch.zeros((0,), dtype=torch.int64).to(device)})\n                continue\n            \n            boxes = torch.tensor([obj['bbox'] for obj in t], dtype=torch.float32)\n            labels = torch.tensor([obj['category_id'] for obj in t], dtype=torch.int64)\n            \n            if boxes.ndim == 1:\n                boxes = boxes.unsqueeze(0)\n            \n            boxes[:, 2:] += boxes[:, :2]\n            \n            keep = (boxes[:, 2] > boxes[:, 0]) & (boxes[:, 3] > boxes[:, 1])\n            valid_targets.append({\n                'boxes': boxes[keep].to(device),\n                'labels': labels[keep].to(device)\n            })\n\n        loss_dict = model(images, valid_targets)\n\n\n        classification_loss = loss_dict.get('classification', torch.tensor(0.0, device=device, requires_grad=True))\n        bbox_regression_loss = loss_dict.get('bbox_regression', torch.tensor(0.0, device=device, requires_grad=True))\n\n\n        loss = classification_loss + bbox_regression_loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        data_loader.set_postfix(loss=running_loss / (i + 1))\n\n        if i % print_freq == 0:\n            print(f\"Epoch: {epoch}, Iteration: {i}, Loss: {loss.item()}\")\ndef evaluate(model, data_loader, device):\n    model.eval()\n    running_loss = 0.0\n    data_loader = tqdm(data_loader, desc=\"Evaluating\", unit=\"batch\")\n    \n    with torch.no_grad():\n        for i, (images, targets) in enumerate(data_loader):\n            images = list(image.to(device) for image in images)\n            valid_targets = []\n            for t in targets:\n                if len(t) == 0:\n                    valid_targets.append({'boxes': torch.zeros((0, 4), dtype=torch.float32).to(device),\n                                          'labels': torch.zeros((0,), dtype=torch.int64).to(device)})\n                    continue\n                \n                boxes = torch.tensor([obj['bbox'] for obj in t], dtype=torch.float32)\n                labels = torch.tensor([obj['category_id'] for obj in t], dtype=torch.int64)\n                \n                if boxes.ndim == 1:\n                    boxes = boxes.unsqueeze(0)\n                \n                boxes[:, 2:] += boxes[:, :2]\n                \n\n                keep = (boxes[:, 2] > boxes[:, 0]) & (boxes[:, 3] > boxes[:, 1])\n                valid_targets.append({\n                    'boxes': boxes[keep].to(device),\n                    'labels': labels[keep].to(device)\n                })\n            \n            outputs = model(images)\n\n            running_loss += sum(loss.item() for loss in outputs.values())\n            data_loader.set_postfix(loss=running_loss / (i + 1))\n            print(outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:15.346915Z","iopub.execute_input":"2024-05-17T15:06:15.347287Z","iopub.status.idle":"2024-05-17T15:06:15.367310Z","shell.execute_reply.started":"2024-05-17T15:06:15.347263Z","shell.execute_reply":"2024-05-17T15:06:15.366309Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:15.368367Z","iopub.execute_input":"2024-05-17T15:06:15.368632Z","iopub.status.idle":"2024-05-17T15:06:15.387405Z","shell.execute_reply.started":"2024-05-17T15:06:15.368609Z","shell.execute_reply":"2024-05-17T15:06:15.386516Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=50)\n    evaluate(model, val_loader, device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T15:06:15.388603Z","iopub.execute_input":"2024-05-17T15:06:15.389430Z","iopub.status.idle":"2024-05-17T16:50:58.183221Z","shell.execute_reply.started":"2024-05-17T15:06:15.389391Z","shell.execute_reply":"2024-05-17T16:50:58.181555Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Epoch 0:   0%|          | 1/29571 [00:03<25:03:38,  3.05s/batch, loss=2.56]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 0, Loss: 2.5584449768066406\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   0%|          | 51/29571 [00:43<6:09:29,  1.33batch/s, loss=1.78]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 50, Loss: 1.3251490592956543\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   0%|          | 101/29571 [01:24<6:37:48,  1.23batch/s, loss=1.46]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 100, Loss: 0.8877701163291931\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|          | 151/29571 [02:04<6:36:06,  1.24batch/s, loss=1.3] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 150, Loss: 0.7371338605880737\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|          | 201/29571 [02:45<7:23:23,  1.10batch/s, loss=1.25]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 200, Loss: 1.7367942333221436\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|          | 251/29571 [03:25<7:03:07,  1.15batch/s, loss=1.24]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 250, Loss: 1.0984268188476562\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|          | 301/29571 [04:04<6:39:46,  1.22batch/s, loss=1.2] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 300, Loss: 0.8813862800598145\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|          | 351/29571 [04:44<6:43:25,  1.21batch/s, loss=1.21]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 350, Loss: 4.4558868408203125\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   1%|▏         | 401/29571 [05:24<6:54:31,  1.17batch/s, loss=1.23]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 400, Loss: 1.0085225105285645\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   2%|▏         | 451/29571 [06:05<6:55:19,  1.17batch/s, loss=1.24]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 450, Loss: 0.976171612739563\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   2%|▏         | 501/29571 [06:44<6:20:54,  1.27batch/s, loss=1.24]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 500, Loss: 1.2045652866363525\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   2%|▏         | 551/29571 [07:25<6:38:44,  1.21batch/s, loss=1.22]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 550, Loss: 0.938727617263794\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   2%|▏         | 601/29571 [08:04<6:05:54,  1.32batch/s, loss=1.21]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 600, Loss: 1.3535099029541016\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   2%|▏         | 651/29571 [08:45<6:29:02,  1.24batch/s, loss=1.2] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 650, Loss: 0.9389598965644836\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   2%|▏         | 701/29571 [09:26<6:19:49,  1.27batch/s, loss=1.2] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 700, Loss: 1.2568880319595337\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   3%|▎         | 751/29571 [10:06<6:32:40,  1.22batch/s, loss=1.18]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 750, Loss: 0.9637616872787476\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   3%|▎         | 801/29571 [10:47<6:28:41,  1.23batch/s, loss=1.17]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 800, Loss: 0.9904544353485107\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   3%|▎         | 851/29571 [11:28<6:52:30,  1.16batch/s, loss=1.15]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 850, Loss: 0.6422180533409119\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   3%|▎         | 901/29571 [12:07<6:37:34,  1.20batch/s, loss=1.14]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 900, Loss: 0.84706711769104\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   3%|▎         | 951/29571 [12:48<6:05:59,  1.30batch/s, loss=1.12]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 950, Loss: 0.7746067047119141\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   3%|▎         | 1001/29571 [13:27<5:22:03,  1.48batch/s, loss=1.11]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1000, Loss: 0.9958347082138062\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   4%|▎         | 1051/29571 [14:08<5:47:32,  1.37batch/s, loss=1.11]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1050, Loss: 0.7329617142677307\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   4%|▎         | 1101/29571 [14:49<6:21:51,  1.24batch/s, loss=1.09]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1100, Loss: 0.9973005056381226\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   4%|▍         | 1151/29571 [15:30<5:50:27,  1.35batch/s, loss=1.08]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1150, Loss: 0.6038447022438049\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   4%|▍         | 1201/29571 [16:09<5:56:42,  1.33batch/s, loss=1.08]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1200, Loss: 0.6395095586776733\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   4%|▍         | 1251/29571 [16:52<6:09:00,  1.28batch/s, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1250, Loss: 0.6234492659568787\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   4%|▍         | 1301/29571 [17:32<6:11:08,  1.27batch/s, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1300, Loss: 0.8990615606307983\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   5%|▍         | 1351/29571 [18:14<6:49:47,  1.15batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1350, Loss: 0.6774499416351318\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   5%|▍         | 1401/29571 [18:55<6:26:56,  1.21batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1400, Loss: 1.3947951793670654\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   5%|▍         | 1451/29571 [19:36<6:18:07,  1.24batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1450, Loss: 1.0327324867248535\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   5%|▌         | 1501/29571 [20:15<6:19:32,  1.23batch/s, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1500, Loss: 1.1637322902679443\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   5%|▌         | 1551/29571 [20:55<5:15:38,  1.48batch/s, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1550, Loss: 1.3578410148620605\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   5%|▌         | 1601/29571 [21:35<6:18:56,  1.23batch/s, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1600, Loss: 1.2591513395309448\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   6%|▌         | 1651/29571 [22:14<5:42:31,  1.36batch/s, loss=1.07]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1650, Loss: 0.7209855318069458\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   6%|▌         | 1701/29571 [22:55<5:59:38,  1.29batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1700, Loss: 1.3535374402999878\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   6%|▌         | 1751/29571 [23:35<6:15:55,  1.23batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1750, Loss: 0.8304822444915771\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   6%|▌         | 1801/29571 [24:17<5:35:47,  1.38batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1800, Loss: 0.6131355166435242\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   6%|▋         | 1851/29571 [24:58<6:04:16,  1.27batch/s, loss=1.06]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1850, Loss: 1.0155150890350342\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   6%|▋         | 1901/29571 [25:38<5:29:32,  1.40batch/s, loss=1.05]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1900, Loss: 0.9218957424163818\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   7%|▋         | 1951/29571 [26:19<6:22:54,  1.20batch/s, loss=1.05]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 1950, Loss: 0.5430458784103394\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   7%|▋         | 2001/29571 [27:00<6:01:20,  1.27batch/s, loss=1.04]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2000, Loss: 0.7996156811714172\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   7%|▋         | 2051/29571 [27:42<6:16:40,  1.22batch/s, loss=1.04]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2050, Loss: 0.7476477026939392\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   7%|▋         | 2151/29571 [29:04<6:37:35,  1.15batch/s, loss=1.04]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2150, Loss: 0.7688581347465515\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   7%|▋         | 2201/29571 [29:45<6:04:21,  1.25batch/s, loss=1.03]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2200, Loss: 0.9622167348861694\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   8%|▊         | 2251/29571 [30:26<5:55:37,  1.28batch/s, loss=1.03]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2250, Loss: 0.7215970754623413\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   8%|▊         | 2301/29571 [31:06<6:35:50,  1.15batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2300, Loss: 0.827655553817749\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   8%|▊         | 2351/29571 [31:46<6:06:34,  1.24batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2350, Loss: 1.04054856300354\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   8%|▊         | 2401/29571 [32:26<6:22:47,  1.18batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2400, Loss: 1.562365174293518\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   8%|▊         | 2451/29571 [33:07<6:10:55,  1.22batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2450, Loss: 0.9429277181625366\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   8%|▊         | 2501/29571 [33:48<5:39:09,  1.33batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2500, Loss: 1.0264711380004883\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   9%|▊         | 2551/29571 [34:29<6:33:52,  1.14batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2550, Loss: 0.7677050232887268\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   9%|▉         | 2601/29571 [35:09<6:01:30,  1.24batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2600, Loss: 0.8180989027023315\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   9%|▉         | 2651/29571 [35:47<6:12:17,  1.21batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2650, Loss: 0.7150247097015381\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   9%|▉         | 2701/29571 [36:28<6:12:54,  1.20batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2700, Loss: 1.002429723739624\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   9%|▉         | 2751/29571 [37:07<5:10:00,  1.44batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2750, Loss: 0.9159128069877625\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:   9%|▉         | 2801/29571 [37:48<5:31:38,  1.35batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2800, Loss: 0.6356573104858398\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  10%|▉         | 2851/29571 [38:28<5:41:36,  1.30batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2850, Loss: 1.2588895559310913\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  10%|▉         | 2901/29571 [39:08<6:17:19,  1.18batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2900, Loss: 0.7353414297103882\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  10%|▉         | 2951/29571 [39:49<6:01:45,  1.23batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 2950, Loss: 0.7811344861984253\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  10%|█         | 3001/29571 [40:30<6:27:04,  1.14batch/s, loss=1]   ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3000, Loss: 0.997367799282074\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  10%|█         | 3051/29571 [41:12<6:18:19,  1.17batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3050, Loss: 0.7586492896080017\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  10%|█         | 3101/29571 [41:53<6:08:30,  1.20batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3100, Loss: 0.7806501984596252\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  11%|█         | 3151/29571 [42:34<6:07:49,  1.20batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3150, Loss: 0.7751734256744385\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  11%|█         | 3201/29571 [43:14<5:39:03,  1.30batch/s, loss=0.998]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3200, Loss: 0.9292445778846741\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  11%|█         | 3251/29571 [43:55<6:17:13,  1.16batch/s, loss=0.996]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3250, Loss: 0.6140727996826172\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  11%|█         | 3301/29571 [44:35<6:20:47,  1.15batch/s, loss=0.996]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3300, Loss: 0.8150427341461182\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  11%|█▏        | 3351/29571 [45:16<5:43:20,  1.27batch/s, loss=0.994]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3350, Loss: 1.0017802715301514\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  12%|█▏        | 3401/29571 [45:55<5:50:41,  1.24batch/s, loss=0.991]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3400, Loss: 0.7302177548408508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  12%|█▏        | 3451/29571 [46:34<4:54:33,  1.48batch/s, loss=0.988]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3450, Loss: 0.6424002051353455\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  12%|█▏        | 3501/29571 [47:14<6:03:51,  1.19batch/s, loss=0.985]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3500, Loss: 0.7271562814712524\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  12%|█▏        | 3551/29571 [47:56<5:59:56,  1.20batch/s, loss=0.982]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3550, Loss: 0.8018633723258972\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  12%|█▏        | 3601/29571 [48:36<5:11:00,  1.39batch/s, loss=0.981]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3600, Loss: 0.7707138061523438\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  12%|█▏        | 3651/29571 [49:15<5:33:09,  1.30batch/s, loss=0.983]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3650, Loss: 1.5262399911880493\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  13%|█▎        | 3701/29571 [49:56<5:47:30,  1.24batch/s, loss=0.99] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3700, Loss: 1.3091509342193604\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  13%|█▎        | 3751/29571 [50:35<5:09:59,  1.39batch/s, loss=0.997]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3750, Loss: 1.5166168212890625\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  13%|█▎        | 3801/29571 [51:15<5:41:36,  1.26batch/s, loss=1]    ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3800, Loss: 1.1218323707580566\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  13%|█▎        | 3851/29571 [51:56<6:08:45,  1.16batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3850, Loss: 0.8289463520050049\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  13%|█▎        | 3901/29571 [52:37<5:35:50,  1.27batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3900, Loss: 0.9247900247573853\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  13%|█▎        | 3951/29571 [53:17<6:18:39,  1.13batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 3950, Loss: 1.0130199193954468\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  14%|█▎        | 4001/29571 [54:00<6:11:55,  1.15batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4000, Loss: 0.9894225001335144\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  14%|█▎        | 4051/29571 [54:40<6:01:38,  1.18batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4050, Loss: 1.079021692276001\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  14%|█▍        | 4101/29571 [55:21<6:10:00,  1.15batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4100, Loss: 0.954132616519928\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  14%|█▍        | 4151/29571 [56:00<5:17:38,  1.33batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4150, Loss: 0.7721267342567444\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  14%|█▍        | 4201/29571 [56:41<5:10:49,  1.36batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4200, Loss: 0.8453388214111328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  14%|█▍        | 4251/29571 [57:20<6:10:03,  1.14batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4250, Loss: 0.8521614670753479\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  15%|█▍        | 4301/29571 [58:00<5:14:10,  1.34batch/s, loss=0.999]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4300, Loss: 1.0069053173065186\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  15%|█▍        | 4351/29571 [58:41<5:45:22,  1.22batch/s, loss=0.997]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4350, Loss: 0.8003000020980835\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  15%|█▍        | 4401/29571 [59:20<5:00:02,  1.40batch/s, loss=0.996]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4400, Loss: 1.0505023002624512\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  15%|█▌        | 4451/29571 [1:00:01<5:55:51,  1.18batch/s, loss=0.995]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4450, Loss: 0.6809003949165344\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  15%|█▌        | 4501/29571 [1:00:41<5:18:44,  1.31batch/s, loss=0.994]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4500, Loss: 0.8076515793800354\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  15%|█▌        | 4551/29571 [1:01:21<5:44:50,  1.21batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4550, Loss: 1.311490535736084\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  16%|█▌        | 4601/29571 [1:02:02<5:32:56,  1.25batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4600, Loss: 0.8919007778167725\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  16%|█▌        | 4651/29571 [1:02:41<5:44:24,  1.21batch/s, loss=0.992]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4650, Loss: 0.9578607678413391\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  16%|█▌        | 4701/29571 [1:03:21<5:44:25,  1.20batch/s, loss=0.991]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4700, Loss: 0.6026515960693359\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  16%|█▌        | 4751/29571 [1:04:02<5:33:15,  1.24batch/s, loss=0.992]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4750, Loss: 0.9154365062713623\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  16%|█▌        | 4801/29571 [1:04:42<5:45:09,  1.20batch/s, loss=0.992]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4800, Loss: 1.0544462203979492\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  16%|█▋        | 4851/29571 [1:05:23<5:51:07,  1.17batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4850, Loss: 1.155287742614746\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  17%|█▋        | 4901/29571 [1:06:03<5:03:03,  1.36batch/s, loss=0.994]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4900, Loss: 0.905718982219696\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  17%|█▋        | 4951/29571 [1:06:44<5:24:59,  1.26batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 4950, Loss: 0.8287535309791565\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  17%|█▋        | 5001/29571 [1:07:24<4:57:54,  1.37batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5000, Loss: 0.9965054988861084\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  17%|█▋        | 5051/29571 [1:08:05<5:55:26,  1.15batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5050, Loss: 1.1698986291885376\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  17%|█▋        | 5101/29571 [1:08:45<4:53:13,  1.39batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5100, Loss: 1.1545238494873047\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  17%|█▋        | 5151/29571 [1:09:26<5:14:25,  1.29batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5150, Loss: 1.0185304880142212\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  18%|█▊        | 5201/29571 [1:10:07<5:01:23,  1.35batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5200, Loss: 0.905238687992096\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  18%|█▊        | 5251/29571 [1:10:47<5:46:41,  1.17batch/s, loss=0.992]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5250, Loss: 0.9193329215049744\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  18%|█▊        | 5301/29571 [1:11:26<5:22:10,  1.26batch/s, loss=0.991]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5300, Loss: 1.0775712728500366\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  18%|█▊        | 5351/29571 [1:12:06<5:43:49,  1.17batch/s, loss=0.99] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5350, Loss: 0.7223323583602905\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  18%|█▊        | 5401/29571 [1:12:48<5:38:51,  1.19batch/s, loss=0.989]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5400, Loss: 0.900412380695343\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  18%|█▊        | 5451/29571 [1:13:28<5:36:17,  1.20batch/s, loss=0.989]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5450, Loss: 1.3376609086990356\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  19%|█▊        | 5501/29571 [1:14:08<5:11:05,  1.29batch/s, loss=0.989]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5500, Loss: 0.6887228488922119\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  19%|█▉        | 5551/29571 [1:14:48<6:00:33,  1.11batch/s, loss=0.989]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5550, Loss: 1.0272034406661987\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  19%|█▉        | 5601/29571 [1:15:30<5:54:14,  1.13batch/s, loss=0.989]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5600, Loss: 0.8808602094650269\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  19%|█▉        | 5651/29571 [1:16:10<5:55:55,  1.12batch/s, loss=0.988]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5650, Loss: 0.9387532472610474\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  19%|█▉        | 5701/29571 [1:16:48<5:07:21,  1.29batch/s, loss=0.988]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5700, Loss: 0.7103009223937988\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  19%|█▉        | 5751/29571 [1:17:29<5:56:49,  1.11batch/s, loss=0.987]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5750, Loss: 0.9138044118881226\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  20%|█▉        | 5801/29571 [1:18:09<5:29:01,  1.20batch/s, loss=0.986]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5800, Loss: 0.6680952310562134\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  20%|█▉        | 5851/29571 [1:18:49<5:40:02,  1.16batch/s, loss=0.985]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5850, Loss: 0.8722472190856934\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  20%|█▉        | 5901/29571 [1:19:30<4:52:55,  1.35batch/s, loss=0.984]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5900, Loss: 0.982546329498291\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  20%|██        | 5951/29571 [1:20:10<5:03:59,  1.29batch/s, loss=0.989]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 5950, Loss: 1.3618931770324707\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  20%|██        | 6001/29571 [1:20:49<4:54:23,  1.33batch/s, loss=0.993]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6000, Loss: 1.3273968696594238\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  20%|██        | 6051/29571 [1:21:28<4:58:10,  1.31batch/s, loss=0.996]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6050, Loss: 1.4900819063186646\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  21%|██        | 6101/29571 [1:22:09<5:05:13,  1.28batch/s, loss=0.998]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6100, Loss: 1.3265788555145264\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  21%|██        | 6151/29571 [1:22:49<5:38:01,  1.15batch/s, loss=1]    ","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6150, Loss: 1.9955787658691406\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  21%|██        | 6201/29571 [1:23:30<5:51:31,  1.11batch/s, loss=1]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6200, Loss: 0.9365532994270325\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  21%|██        | 6251/29571 [1:24:11<5:26:17,  1.19batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6250, Loss: 1.1350319385528564\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  21%|██▏       | 6301/29571 [1:24:50<5:32:04,  1.17batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6300, Loss: 1.1146891117095947\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  21%|██▏       | 6351/29571 [1:25:29<4:49:10,  1.34batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6350, Loss: 1.219698190689087\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  22%|██▏       | 6401/29571 [1:26:12<5:36:18,  1.15batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6400, Loss: 1.0182439088821411\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  22%|██▏       | 6451/29571 [1:26:53<5:43:00,  1.12batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6450, Loss: 1.2695486545562744\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  22%|██▏       | 6501/29571 [1:27:34<5:20:04,  1.20batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6500, Loss: 1.0675909519195557\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  22%|██▏       | 6551/29571 [1:28:14<5:10:33,  1.24batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6550, Loss: 0.962177038192749\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  22%|██▏       | 6601/29571 [1:28:53<4:28:12,  1.43batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6600, Loss: 1.0762782096862793\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  22%|██▏       | 6651/29571 [1:29:35<5:43:54,  1.11batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6650, Loss: 1.2094782590866089\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  23%|██▎       | 6701/29571 [1:30:17<5:36:21,  1.13batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6700, Loss: 0.9089945554733276\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  23%|██▎       | 6751/29571 [1:30:57<5:22:01,  1.18batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6750, Loss: 1.0517241954803467\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  23%|██▎       | 6801/29571 [1:31:38<5:16:08,  1.20batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6800, Loss: 0.9959408044815063\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  23%|██▎       | 6851/29571 [1:32:18<4:48:18,  1.31batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6850, Loss: 1.1867375373840332\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  23%|██▎       | 6901/29571 [1:33:00<5:29:39,  1.15batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6900, Loss: 1.0225059986114502\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  24%|██▎       | 6951/29571 [1:33:41<5:27:03,  1.15batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 6950, Loss: 0.9654570817947388\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  24%|██▎       | 7001/29571 [1:34:23<4:45:32,  1.32batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7000, Loss: 0.9936019778251648\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  24%|██▍       | 7051/29571 [1:35:04<5:09:44,  1.21batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7050, Loss: 1.022780418395996\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  24%|██▍       | 7101/29571 [1:35:44<5:06:41,  1.22batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7100, Loss: 1.3136519193649292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  24%|██▍       | 7151/29571 [1:36:24<5:04:36,  1.23batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7150, Loss: 1.0449111461639404\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  24%|██▍       | 7201/29571 [1:37:04<4:39:15,  1.34batch/s, loss=1.02]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7200, Loss: 1.201991319656372\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  25%|██▍       | 7251/29571 [1:37:44<4:43:21,  1.31batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7250, Loss: 1.1133041381835938\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  25%|██▍       | 7301/29571 [1:38:26<4:59:00,  1.24batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7300, Loss: 0.7504031658172607\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  25%|██▍       | 7351/29571 [1:39:07<4:52:08,  1.27batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7350, Loss: 0.9096827507019043\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  25%|██▌       | 7401/29571 [1:39:46<5:08:09,  1.20batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7400, Loss: 0.8868407607078552\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  25%|██▌       | 7451/29571 [1:40:26<5:11:13,  1.18batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7450, Loss: 0.8563796281814575\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  25%|██▌       | 7501/29571 [1:41:05<4:43:36,  1.30batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7500, Loss: 1.0367681980133057\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  26%|██▌       | 7551/29571 [1:41:47<4:55:34,  1.24batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7550, Loss: 0.870927095413208\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  26%|██▌       | 7601/29571 [1:42:28<5:09:12,  1.18batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7600, Loss: 1.0566192865371704\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  26%|██▌       | 7651/29571 [1:43:09<5:26:07,  1.12batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7650, Loss: 0.8886857032775879\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  26%|██▌       | 7701/29571 [1:43:48<4:58:54,  1.22batch/s, loss=1.01]","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Iteration: 7700, Loss: 0.7419942617416382\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0:  26%|██▌       | 7742/29571 [1:44:41<4:55:12,  1.23batch/s, loss=1.01]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     evaluate(model, val_loader, device)\n","Cell \u001b[0;32mIn[10], line 35\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[1;32m     29\u001b[0m     keep \u001b[38;5;241m=\u001b[39m (boxes[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m>\u001b[39m boxes[:, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m&\u001b[39m (boxes[:, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m>\u001b[39m boxes[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     30\u001b[0m     valid_targets\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m: boxes[keep]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels[keep]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m     })\n\u001b[0;32m---> 35\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Handle missing keys more gracefully\u001b[39;00m\n\u001b[1;32m     38\u001b[0m classification_loss \u001b[38;5;241m=\u001b[39m loss_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/retinanet.py:645\u001b[0m, in \u001b[0;36mRetinaNet.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    642\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_assert(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets should not be none when in training mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;66;03m# compute the losses\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# recover level sizes\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     num_anchors_per_level \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m features]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/retinanet.py:501\u001b[0m, in \u001b[0;36mRetinaNet.compute_loss\u001b[0;34m(self, targets, head_outputs, anchors)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    500\u001b[0m     match_quality_matrix \u001b[38;5;241m=\u001b[39m box_ops\u001b[38;5;241m.\u001b[39mbox_iou(targets_per_image[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m], anchors_per_image)\n\u001b[0;32m--> 501\u001b[0m     matched_idxs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproposal_matcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_quality_matrix\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead\u001b[38;5;241m.\u001b[39mcompute_loss(targets, head_outputs, anchors, matched_idxs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/_utils.py:394\u001b[0m, in \u001b[0;36mMatcher.__call__\u001b[0;34m(self, match_quality_matrix)\u001b[0m\n\u001b[1;32m    392\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_assert(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_matches should not be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_low_quality_matches_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatch_quality_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matches\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/_utils.py:409\u001b[0m, in \u001b[0;36mMatcher.set_low_quality_matches_\u001b[0;34m(self, matches, all_matches, match_quality_matrix)\u001b[0m\n\u001b[1;32m    407\u001b[0m highest_quality_foreach_gt, _ \u001b[38;5;241m=\u001b[39m match_quality_matrix\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Find the highest quality match available, even if it is low, including ties\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m gt_pred_pairs_of_highest_quality \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_quality_matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhighest_quality_foreach_gt\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Example gt_pred_pairs_of_highest_quality:\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# (tensor([0, 1, 1, 2, 2, 3, 3, 4, 5, 5]),\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m#  tensor([39796, 32055, 32070, 39190, 40255, 40390, 41455, 45470, 45325, 46390]))\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# Each element in the first tensor is a gt index, and each element in second tensor is a prediction index\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Note how gt items 1, 2, 3, and 5 each have two ties\u001b[39;00m\n\u001b[1;32m    416\u001b[0m pred_inds_to_update \u001b[38;5;241m=\u001b[39m gt_pred_pairs_of_highest_quality[\u001b[38;5;241m1\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}